{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mplfinance as fplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(data_path):\n",
    "    df = pd.read_csv(data_path,\n",
    "                         sep='\\t',\n",
    "                         names=['DateTime', 'Open', 'High', 'Low', 'Close', 'Volume'],\n",
    "                         skiprows=1\n",
    "                         )\n",
    "    df[['Open','High','Low','Close']] = df[['Open','High','Low','Close']].apply(pd.to_numeric, errors='coerce')  \n",
    "    df['Ticker'] = data_path\n",
    "    df = df.tail(50000) #for testing purpose\n",
    "    df.index = pd.DatetimeIndex(df['DateTime'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_ts(df, s, ts=0.0001, max_len=144,dir='buy'):\n",
    "    if dir=='buy':\n",
    "        tsl=0\n",
    "    else:\n",
    "        tsl=np.inf\n",
    "    for i in range(s,s+max_len):\n",
    "        if dir=='buy':\n",
    "            tsl = max(tsl, df.High.values[i] - ts)\n",
    "            if df.Low.values[i]<tsl:\n",
    "                return tsl\n",
    "        else: \n",
    "            tsl = max(tsl, df.Low.values[i] + ts)\n",
    "            if df.High.values[i]>tsl:\n",
    "                return tsl            \n",
    "    return df.Close.values[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"D:\\\\A484018\\\\dev\\\\GBPJPY_M5.csv\",\n",
    "              \"D:\\\\A484018\\\\dev\\\\EURUSD_M5.csv\",\n",
    "              \"D:\\\\A484018\\\\dev\\\\AUDCHF_M5.csv\"]\n",
    "              \n",
    "dfs = [load_file(f) for f in data_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |----------------------------------------------------------------------------------------------------| 0.6% \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\homeware\\miniconda3-windows-x86_64\\lib\\site-packages\\ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      " |████████████████████████████------------------------------------------------------------------------| 28.9% \r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-1bf5d5511e56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\homeware\\miniconda3-windows-x86_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \"\"\"\n\u001b[1;32m-> 1188\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\homeware\\miniconda3-windows-x86_64\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    #row_size = 0.0001 #EURUSD\n",
    "    row_size = df.Close.mean() * 0.001\n",
    "\n",
    "    clen=144\n",
    "    fblen=12\n",
    "    oblen=12\n",
    "    shift=120\n",
    "\n",
    "    #trailing_stop=0.0010 #EURUSD\n",
    "    trailing_stop=df.Close.mean() * 0.01\n",
    "    max_trd_len=96\n",
    "\n",
    "    break_step = df.Close.mean() * 0.001\n",
    "    study_step=1\n",
    "\n",
    "    l_min = df.Low.min()\n",
    "    h_max = df.High.max()\n",
    "\n",
    "    df['first_row'] = np.rint((df.Low-l_min) / row_size).astype(int)\n",
    "    df['last_row'] = np.rint((df.High-l_min) / row_size).astype(int)\n",
    "\n",
    "    npdf=np.zeros((11,len(df)))\n",
    "    for s in range(clen,len(df)-clen-oblen,study_step):\n",
    "\n",
    "        printProgressBar (s-clen, len(df)-2*clen-oblen-1, prefix = '', suffix = '')\n",
    "\n",
    "        sub_df = df[s-clen:s]\n",
    "        r_min =  sub_df.first_row.min() \n",
    "        c = np.zeros(sub_df.last_row.max() - r_min)       \n",
    "        for v,a,b in zip(sub_df.Volume.values, sub_df.first_row, sub_df.last_row):\n",
    "            c[a-r_min:b+1-r_min] += (v/(1+b-a))     \n",
    "        id = np.arange(sub_df.first_row.min(),sub_df.last_row.max())\n",
    "        idx = np.round(l_min + (row_size/2) + id*row_size,4)          \n",
    "        profile = pd.Series(data=c, index=idx)\n",
    "\n",
    "        stats = np.zeros((len(profile),len(profile)))\n",
    "        for w in range(len(profile)//3,2*len(profile)//3):\n",
    "            for i in range(0,len(profile)-w):\n",
    "                stats[w,i]=profile.values[i:i+w].sum()/np.power(w,0.75)\n",
    "\n",
    "        w,i = np.unravel_index(np.argmax(stats),stats.shape)\n",
    "\n",
    "        c = ['blue']*len(profile)\n",
    "        c[i:i + (w)] = ['red']*(w)\n",
    "\n",
    "        chan_dn=profile.index[i] - break_step\n",
    "        chan_up=profile.index[i+w] + break_step\n",
    "\n",
    "        #Profile stats\n",
    "        st1 = np.round(100*profile.values[i:i + w].sum() / profile.values.sum(),2)\n",
    "        st2 = np.round(100*w/len(profile),2)\n",
    "        st3 = np.round(100*(i+i+w)/(2*len(profile)),2)\n",
    "\n",
    "        # final balance\n",
    "        fb_up,fb_mid,fb_dn=0,0,0\n",
    "        for j in range(s-fblen,s):\n",
    "            fb_up += max(0,df.High.values[j] - chan_up) - max(0,df.Low.values[j] - chan_up)\n",
    "            fb_mid += max(0,(df.High.values[j] - df.Low.values[j]) - max(0,df.High.values[j] - chan_up) - max(0,chan_dn - df.Low.values[j]))\n",
    "            fb_dn += max(0,chan_dn - df.Low.values[j]) - max(0,chan_dn - df.High.values[j])\n",
    "\n",
    "        tot = fb_up+fb_mid+fb_dn\n",
    "        fb_up = np.round(100*fb_up/tot,2)\n",
    "        fb_mid = np.round(100*fb_mid/tot,2)\n",
    "        fb_dn = np.round(100*fb_dn/tot,2)\n",
    "\n",
    "        #output\n",
    "        ob_up,ob_mid,ob_dn=0,0,0\n",
    "        for j in range(s,s+oblen):\n",
    "            ob_up += max(0,df.High.values[j] - chan_up) - max(0,df.Low.values[j] - chan_up)\n",
    "            ob_mid += max(0,(df.High.values[j] - df.Low.values[j]) - max(0,df.High.values[j] - chan_up) - max(0,chan_dn - df.Low.values[j]))\n",
    "            ob_dn += max(0,chan_dn - df.Low.values[j]) - max(0,chan_dn - df.High.values[j])\n",
    "\n",
    "        tot = ob_up+ob_mid+ob_dn\n",
    "        ob_up = np.round(100*ob_up/tot,2)\n",
    "        ob_mid = np.round(100*ob_mid/tot,2)\n",
    "        ob_dn = np.round(100*ob_dn/tot,2)\n",
    "\n",
    "        #trailling stop results\n",
    "        ts_buy=sim_ts(df,s,ts=trailing_stop, max_len=max_trd_len,dir='buy')\n",
    "        ts_sell=sim_ts(df,s,ts=trailing_stop, max_len=max_trd_len,dir='sell')\n",
    "\n",
    "        npdf[:,s] = [ts_buy,ts_sell,st1,st2,st3,fb_up,fb_mid,fb_dn,ob_up,ob_mid,ob_dn]\n",
    "\n",
    "        \"\"\"    \n",
    "        print('----------------------------------------------------------')\n",
    "        print(s,df.DateTime.values[s])\n",
    "        print('main profile:', st1,'%   /', st2,'%   /', st3,'%')\n",
    "        print('final balance:', fb_up,'%   /', fb_mid,'%   /', fb_dn,'%')\n",
    "        print('output balance:', ob_up,'%   /', ob_mid,'%   /', ob_dn,'%')\n",
    "        \"\"\"\n",
    "\n",
    "    df[['ts_buy','ts_sell','mp%_in','mp%_size', 'mp%_dir','fb_up','fb_mid','fb_dn','ob_up','ob_mid','ob_dn']]=npdf.T\n",
    "    df[['mp%_in_shift','mp%_size_shift', 'mp%_dir_shift']] = df[['mp%_in','mp%_size', 'mp%_dir']].shift(shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    df['buy_profit'] = df.ts_buy - df.Close \n",
    "    df['sell_profit']= df.Close - df.ts_sell\n",
    "\n",
    "    df['adj_close'] = (df.High + df.Low + df.Close)/3\n",
    "\n",
    "    df['sma12_var'] = (df['adj_close']/df['adj_close'].rolling(12).mean())-1\n",
    "    df['sma48_var'] = (df['adj_close']/df['adj_close'].rolling(48).mean())-1\n",
    "    df['sma180_var'] = (df['adj_close']/df['adj_close'].rolling(180).mean())-1\n",
    "\n",
    "    df['spread']=((df['adj_close']/df['Open'])-1).abs()\n",
    "    df['spread14_e']=df['spread'].ewm(span=14).mean()\n",
    "\n",
    "    df['volume14_34_var'] = (df['Volume'].rolling(14).mean()/df['Volume'].rolling(34).mean())-1\n",
    "    df['volume14_34_var'] = df['volume14_34_var'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['mp%_in', 'mp%_size', 'mp%_dir',\n",
    "       'fb_up', 'fb_mid', 'fb_dn', 'ob_up', 'ob_mid', 'ob_dn', 'mp%_in_shift',\n",
    "       'mp%_size_shift', 'mp%_dir_shift',\n",
    "       'sma12_var', 'sma48_var', 'sma180_var', 'spread',\n",
    "       'spread14_e', 'volume14_34_var']\n",
    "\n",
    "dfs2=[]\n",
    "for df in dfs:\n",
    "    df.buy_profit = df.buy_profit.shift(-oblen)\n",
    "    df['labels'] = (df.buy_profit > df.Close.mean() * 0.002)\n",
    "\n",
    "    dfs2.append(df.dropna().copy())\n",
    "    \n",
    "df2 = pd.concat(dfs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2[features]\n",
    "y = df2['labels'].astype('int')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier(max_depth=10, random_state=411)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "DT = DecisionTreeClassifier(max_depth=16, random_state=411)\n",
    "DT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_DT = DT.predict(X_test)\n",
    "y_pred_RF = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RND full score:', y.sum()/y.count())\n",
    "print('DT train score:',DT.score(X_train,y_train))\n",
    "print(\"DT test_score:\", DT.score(X_test,y_test))\n",
    "print('RF train score:',RF.score(X_train,y_train))\n",
    "print(\"RF test_score:\", RF.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('depth:',DT.get_depth())\n",
    "print('n_leaves:',DT.get_n_leaves())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_representation = sklearn.tree.export_text(DT, max_depth=2, feature_names=list(features), show_weights=True)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = DT.feature_importances_\n",
    "std = np.std(DT.feature_importances_)\n",
    "forest_importances = pd.Series(importances, index=features)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred_DT)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = [tree.get_depth() for tree in RF.estimators_]\n",
    "n_leaves = [tree.get_n_leaves() for tree in RF.estimators_]\n",
    "print('depth:',np.min(depth),np.max(depth),np.mean(depth))\n",
    "print('n_leaves:',np.min(n_leaves),np.max(n_leaves),np.mean(n_leaves),np.sum(n_leaves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = RF.feature_importances_\n",
    "std = np.std([t.feature_importances_ for t in RF.estimators_], axis=0)\n",
    "forest_importances = pd.Series(importances, index=features)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_test, y_pred_RF)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.sum((y_pred_DT == 1) & (y_test==1))\n",
    "l = np.sum((y_pred_DT == 1) & (y_test==0))\n",
    "print('score:',w/(w+l))\n",
    "print('roc score:',roc_auc_score(y_test, y_pred_DT))\n",
    "print('count:',np.sum(y_pred_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = X_test[y_pred_RF == 1].sort_index().index.values\n",
    "mask=np.concatenate(([True],np.diff(indexes,1).astype(float) > 3.2000e+13))\n",
    "df2.loc[indexes[mask]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"s=200\n",
    "ts = pd.to_datetime(str(df.index.values[s])) \n",
    "\n",
    "fplt.plot(\n",
    "    df[s-10:s+100],\n",
    "    type='candle',\n",
    "    style='charles',\n",
    "    hlines=[chan_dn,chan_up],\n",
    "    vlines = ts.strftime('%Y-%m-%d %H:%M')\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97ae724bfa85b9b34df7982b8bb8c7216f435b92902d749e4263f71162bea840"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
